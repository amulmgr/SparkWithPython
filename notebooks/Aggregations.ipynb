{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required modules and Initialize SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\dev-tools\\\\spark-3.0.0-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Aggregations\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Course', 'Fee']\n",
      "[(2017, 'Spark', 15000), (2017, 'Hadoop', 10000), (2017, 'Scala', 10000), (2017, 'HBase', 10000), (2017, 'Java', 10000), (2016, 'Spark', 20000), (2016, 'Hadoop', 15000), (2016, 'Scala', 10000), (2016, 'HBase', 10000), (2016, 'Java', 10000), (2015, 'Spark', 20000), (2015, 'Hadoop', 20000), (2015, 'Scala', 10000), (2015, 'HBase', 10000), (2015, 'Java', 10000), (2014, 'Cassandra', 20000), (2014, 'Hadoop', 20000), (2014, 'Android', 15000), (2014, 'HBase', 15000), (2014, 'Java', 10000)]\n"
     ]
    }
   ],
   "source": [
    "schema = ['Year','Course','Fee']\n",
    "data = [(2017,'Spark',15000),(2017,'Hadoop',10000),(2017,'Scala',10000),(2017,'HBase',10000),(2017,'Java',10000),\n",
    "       (2016,'Spark',20000),(2016,'Hadoop',15000),(2016,'Scala',10000),(2016,'HBase',10000),(2016,'Java',10000),\n",
    "       (2015,'Spark',20000),(2015,'Hadoop',20000),(2015,'Scala',10000),(2015,'HBase',10000),(2015,'Java',10000),\n",
    "       (2014,'Cassandra',20000),(2014,'Hadoop',20000),(2014,'Android',15000),(2014,'HBase',15000),(2014,'Java',10000)]\n",
    "print(schema)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "courses_df = spark.createDataFrame(data,schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Year: long (nullable = true)\n",
      " |-- Course: string (nullable = true)\n",
      " |-- Fee: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "courses_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+-----+\n",
      "|Year|   Course|  Fee|\n",
      "+----+---------+-----+\n",
      "|2017|    Spark|15000|\n",
      "|2017|   Hadoop|10000|\n",
      "|2017|    Scala|10000|\n",
      "|2017|    HBase|10000|\n",
      "|2017|     Java|10000|\n",
      "|2016|    Spark|20000|\n",
      "|2016|   Hadoop|15000|\n",
      "|2016|    Scala|10000|\n",
      "|2016|    HBase|10000|\n",
      "|2016|     Java|10000|\n",
      "|2015|    Spark|20000|\n",
      "|2015|   Hadoop|20000|\n",
      "|2015|    Scala|10000|\n",
      "|2015|    HBase|10000|\n",
      "|2015|     Java|10000|\n",
      "|2014|Cassandra|20000|\n",
      "|2014|   Hadoop|20000|\n",
      "|2014|  Android|15000|\n",
      "|2014|    HBase|15000|\n",
      "|2014|     Java|10000|\n",
      "+----+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "courses_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform aggregation on the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_df = courses_df.groupBy('Year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GroupedData' object has no attribute 'show'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-15a424bb3b3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgroup_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GroupedData' object has no attribute 'show'"
     ]
    }
   ],
   "source": [
    "group_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.group.GroupedData"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(group_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Year|count|\n",
      "+----+-----+\n",
      "|2014|    5|\n",
      "|2016|    5|\n",
      "|2017|    5|\n",
      "|2015|    5|\n",
      "+----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_df.count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|Year|sum(Fee)|\n",
      "+----+--------+\n",
      "|2014|   80000|\n",
      "|2016|   65000|\n",
      "|2017|   55000|\n",
      "|2015|   70000|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find earning per Year\n",
    "group_df.sum('Fee').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|Year|avg(Fee)|\n",
      "+----+--------+\n",
      "|2014| 16000.0|\n",
      "|2016| 13000.0|\n",
      "|2017| 11000.0|\n",
      "|2015| 14000.0|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find average earning per Year\n",
    "group_df.avg('Fee').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+--------+----------------+--------------+\n",
      "|Year|  Min|  Max|Earnings|Average Earnings|Num of Courses|\n",
      "+----+-----+-----+--------+----------------+--------------+\n",
      "|2014|10000|20000|   80000|         16000.0|             5|\n",
      "|2016|10000|20000|   65000|         13000.0|             5|\n",
      "|2017|10000|15000|   55000|         11000.0|             5|\n",
      "|2015|10000|20000|   70000|         14000.0|             5|\n",
      "+----+-----+-----+--------+----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "group_df.agg(F.min('Fee').alias('Min'), \n",
    "             F.max('Fee').alias('Max'),\n",
    "             F.sum('Fee').alias('Earnings'),\n",
    "             F.avg('Fee').alias('Average Earnings'),\n",
    "             F.count('*').alias('Num of Courses')\n",
    "            ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+-----+-----+-----+--------+-------+\n",
      "|Year| Java|Hadoop|HBase|Scala|Spark|Casandra|Android|\n",
      "+----+-----+------+-----+-----+-----+--------+-------+\n",
      "|2014|10000| 20000|15000| null| null|    null|  15000|\n",
      "|2016|10000| 15000|10000|10000|20000|    null|   null|\n",
      "|2017|10000| 10000|10000|10000|15000|    null|   null|\n",
      "|2015|10000| 20000|10000|10000|20000|    null|   null|\n",
      "+----+-----+------+-----+-----+-----+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the sum of earnings for each year by course with each course as a separate column\n",
    "group_df.pivot('Course',['Java','Hadoop','HBase','Scala','Spark','Casandra','Android']).sum('Fee').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+\n",
      "|approx_count_distinct(Course)|\n",
      "+-----------------------------+\n",
      "|                            7|\n",
      "+-----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get count of distinct items in a group.\n",
    "courses_df.select(F.approx_count_distinct(\"Course\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|collect_list(Course)                                                                                                                              |\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[Spark, Hadoop, Scala, HBase, Java, Spark, Hadoop, Scala, HBase, Java, Spark, Hadoop, Scala, HBase, Java, Cassandra, Hadoop, Android, HBase, Java]|\n",
      "+--------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all values from an input column (with duplicates)\n",
    "courses_df.select(F.collect_list(\"Course\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+\n",
      "|collect_set(Course)                                    |\n",
      "+-------------------------------------------------------+\n",
      "|[Scala, Spark, Java, Cassandra, HBase, Android, Hadoop]|\n",
      "+-------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all values from an input column (without duplicates)\n",
    "courses_df.select(F.collect_set(\"Course\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|count(Course)|\n",
      "+-------------+\n",
      "|           20|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "courses_df.select(F.count(\"Course\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
